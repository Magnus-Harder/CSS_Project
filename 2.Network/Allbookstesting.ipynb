{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chapter(Book):\n",
    "    split_string = \"\\n{9}|\\n{8}|\\n{7}|\\n{6}|\\n{5}[0-9]+\\s?\\n{5}\"\n",
    "    Chapters_text = {idx+1 : chapter for idx, chapter in enumerate(re.split(split_string, Book[7:]))}\n",
    "\n",
    "    return Chapters_text\n",
    "\n",
    "\n",
    "def split_pages(Chapter,split_string):\n",
    "    Pages_text = re.split(split_string,Chapter)\n",
    "    return Pages_text\n",
    "\n",
    "def format_page(Page):\n",
    "    Page = re.sub(\"\\n+|\\t\",\"\",Page)\n",
    "    Page = tokenize.sent_tokenize(Page)\n",
    "    return Page\n",
    "\n",
    "\n",
    "def split_book(Book,split_string):\n",
    "    Chapters_text = split_chapter(Book)\n",
    "    for chapter in Chapters_text:\n",
    "        Pages_text = split_pages(Chapters_text[chapter],split_string)\n",
    "        Pages_text = [format_page(Page) for Page in Pages_text[:-1]]\n",
    "        Chapters_text[chapter] = Pages_text\n",
    "\n",
    "    for chapter in Chapters_text:\n",
    "        for idx,page in enumerate(Chapters_text[chapter]):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if not page[0][0].isupper():\n",
    "\n",
    "                    Chapters_text[chapter][idx-1][-1] = Chapters_text[chapter][idx-1][-1] + \" \" + page[0]\n",
    "                    \n",
    "                    Chapters_text[chapter][idx] = page[1:]\n",
    "                \n",
    "    return Chapters_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Links for each book\n",
    "Books = [\n",
    "    #1\n",
    "    \"Book 1 - The Philosopher's Stone.txt\",\n",
    "    #2\n",
    "    'Book 2 - The Chamber of Secrets.txt',\n",
    "    #3\n",
    "    'Book 3 - The Prisoner of Azkaban.txt',\n",
    "    #4\n",
    "    'Book 4 - The Goblet of Fire.txt',\n",
    "    #5\n",
    "    'Book 5 - The Order of the Phoenix.txt',\n",
    "    #6\n",
    "    'Book 6 - The Half Blood Prince.txt',\n",
    "    #7\n",
    "    'Book 7 - The Deathly Hallows.txt'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[0]}\", encoding=\"utf8\") as f:\n",
    "    Book1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 1 has: 347 Pages\n",
      "Book 1 has: 17 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text1 = split_book(Book1,split_string=\"Page \\| [0-9]+ Harry Potter and the Philosophers Stone -\\s?J.K. Rowling\")\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text1:\n",
    "    pages += len(Chapters_text1[chapter])\n",
    "print(\"Book 1 has:\",pages,\"Pages\")\n",
    "print(\"Book 1 has:\",len(Chapters_text1),\"Chapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book1.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text1,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[1]}\", encoding=\"utf8\") as f:\n",
    "    Book2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 2 has: 379 Pages\n",
      "Book 2 has: 18 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text2 = split_book(Book2,split_string=\"Page \\| [0-9]+ Harry Potter and the Chamber of Secrets -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "#Missing split at page 24, 37, 116, 140, 180\n",
    "\n",
    "#text in original .txt file:\n",
    "#P a g e | 24 Harry Potter and the Chamber of Secrets - J.K. Rowling\n",
    "#P a g e | 37 Harry Potter and the Chamber of Secrets - J.K. Rowling\n",
    "#Page | 116 Harry Potter and the Chamber of Secrets- J.K. Rowling\n",
    "#Page | 140 Harry Potter and the Chamber of Secrets- J.K. Rowling\n",
    "#Page | 180 Harry Potter and the Chamber of Secrets- J.K. Rowling \n",
    "\n",
    "# Has been corrected to\n",
    "#Page | XX Harry Potter and the Chamber of Secrets - J.K. Rowling \n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text2:\n",
    "    pages += len(Chapters_text2[chapter])\n",
    "print(\"Book 2 has:\",pages,\"Pages\")\n",
    "print(\"Book 2 has:\",len(Chapters_text2),\"Chapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book2.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text2,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[2]}\", encoding=\"utf8\") as f:\n",
    "    Book3 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 3 has: 486 Pages\n",
      "Book 3 has: 22 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text3 = split_book(Book3,split_string=\"Page \\| [0-9]+ Harry Potter and the Prisoner of Azkaban -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text3:\n",
    "    pages += len(Chapters_text3[chapter])\n",
    "print(\"Book 3 has:\",pages,\"Pages\")\n",
    "print(\"Book 3 has:\",len(Chapters_text3),\"Chapters\")\n",
    "#One chapter was not split properly (FLIGHT OF THE FAT LADY)\n",
    "# txt. file has been changed to properly catch all chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book3.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text3,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[3]}\", encoding=\"utf8\") as f:\n",
    "    Book4 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 4 has: 810 Pages\n",
      "Book 4 has: 37 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text4 = split_book(Book4,split_string=\"P\\s?a\\s?g\\s?e\\s?\\|\\s?[0-9]+\\s?\\n*\\s?Harry Potter and the Goblet of Fire -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text4:\n",
    "    pages += len(Chapters_text4[chapter])\n",
    "print(\"Book 4 has:\",pages,\"Pages\")\n",
    "print(\"Book 4 has:\",len(Chapters_text4),\"Chapters\")\n",
    "#One chapter has not been split properly (THE GOBLET OF FIRE)\n",
    "#.txt file has been changed to deal with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book4.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text4,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[4]}\", encoding=\"utf8\") as f:\n",
    "    Book5 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 5 has: 1107 Pages\n",
      "Book 5 has: 38 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text5 = split_book(Book5,split_string=\"P\\s?a\\s?g\\s?e\\s?\\|\\s?[0-9lUO]+\\s?\\n*\\s*Harry Potter and the Order of the Phoenix -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text5:\n",
    "    pages += len(Chapters_text5[chapter])\n",
    "print(\"Book 5 has:\",pages,\"Pages\")\n",
    "print(\"Book 5 has:\",len(Chapters_text5),\"Chapters\")\n",
    "#One chapter has not been split properly (THE SORTING HATâ€™S NEW SONG)\n",
    "#.txt file has been changed to deal with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book5.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text5,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[5]}\", encoding=\"utf8\") as f:\n",
    "    Book6 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 6 has: 729 Pages\n",
      "Book 6 has: 30 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text6 = split_book(Book6,split_string=\"P\\s?a\\s?g\\s?e\\s?\\|\\s?[0-9lUO]+\\s?\\n*\\s*Harry Potter and the Half Blood Prince -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text6:\n",
    "    pages += len(Chapters_text6[chapter])\n",
    "print(\"Book 6 has:\",pages,\"Pages\")\n",
    "print(\"Book 6 has:\",len(Chapters_text6),\"Chapters\")\n",
    "#One chapter too much due to errors in .txt file\n",
    "# Has been fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book6.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text6,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "with open(f\"1.Dataset_files/OriginalBooks/{Books[6]}\", encoding=\"utf8\") as f:\n",
    "    Book7 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 7 has: 855 Pages\n",
      "Book 7 has: 37 Chapters\n"
     ]
    }
   ],
   "source": [
    "Chapters_text7 = split_book(Book7,split_string=\"P\\s?a\\s?g\\s?e\\s?\\|\\s?[0-9lUO]+\\s?\\n*\\s*Harry Potter and the Deathly Hallows -\\s?J.K. Rowling\")\n",
    "\n",
    "\n",
    "pages = 0\n",
    "for chapter in Chapters_text7:\n",
    "    pages += len(Chapters_text7[chapter])\n",
    "print(\"Book 7 has:\",pages,\"Pages\")\n",
    "print(\"Book 7 has:\",len(Chapters_text7),\"Chapters\")\n",
    "#One chapter too much due to errors in .txt file\n",
    "# Has been fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"1.Dataset_files/Books_formatted/Book7.pkl\",\"wb\") as f:\n",
    "    pkl.dump(Chapters_text7,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
