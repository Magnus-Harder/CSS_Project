{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "# What went well?\n",
    "\n",
    "Many of the methods we have used throughout this project are primarily used for static networks. This is however in contrast with our original idea of a temporal network that dynamically changes throughout the books. Therefore our handling of data has suited us well, which has allowed us to tap into specific chapters and parts of the books, as well as being able to both look at the accumulated network for a given time. This freedom in our network allows us to both look at key moment details as well as viewing the bigger picture.\n",
    "\n",
    "\n",
    "# What is still missing? What could be improved? Why?\n",
    "Something that perhaps is worth investigating could be to see the word clouds for the communities in each key moment. Looking at the clouds for key characters is also relevant, however this disregards some of the narative that perhaps the entire community tells better. These word clouds could perhaps reveal even more about the key moments that we are currently not covering.\n",
    "\n",
    "Another point of interest is the fact that temproal networks like the one we use are not suited for showing the vast amount of interconnections between characters over time. The growing network ensures that central characters in the books become more and more clear. However this also brings issues when wanting to analyse specific parts of the books. This is because changes early in the books have bigger relative impact on the network compared to some of the final chapters. Therefore it would be nice to add some sort of exponential weight decay to the network weights, so that recent connections in the network always result in the biggest changes to the network. This would make examining key moments more interesting, since some past connections would still be present, without having to ignore the entire past of the story like we are doing now.\n",
    "\n",
    "It would also be interesting to experiment with the window size when creating both our dynamic text, as well as our network. Perhaps some of the connections that are naratively quite strong, because an event will often take cause over multiple pages. Experimenting with this window size could prove to reveal new and stronger connections between characters. Adjusting the text window size could maybe also help getting a bigger picture of characters, although also introducing more noice.\n",
    "\n",
    "Another problem we found when creating defining the key moments is that sometimes it is difficult to say exactly where the moments happen. We have regarded these moments on a chapter by chapter basis, however in reality this should probably be seperated either at sentence or page level for a more accurate speration. This is also a general difficulty when working with a large corpus. There are a lot of edge cases that has to be manually solved on a case by case basis. This also includes characters having identical names and aliases to other characters, where we have chosen to prioritise the first mentioned characters in these cases.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
